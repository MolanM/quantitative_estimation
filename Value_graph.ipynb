{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation on value graph\n",
    "\n",
    "1. Martin Molan\n",
    "1. Gregor Molan\n",
    "\n",
    "2021-05-01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Value-graph\" data-toc-modified-id=\"Value-graph-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Value graph</a></span><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Definition-of-model-topology\" data-toc-modified-id=\"Definition-of-model-topology-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Definition of model topology</a></span></li><li><span><a href=\"#Definition-of-input-parameters-(graph-edge-weights)\" data-toc-modified-id=\"Definition-of-input-parameters-(graph-edge-weights)-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Definition of input parameters (graph edge weights)</a></span></li><li><span><a href=\"#Definition-of-input-variables\" data-toc-modified-id=\"Definition-of-input-variables-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Definition of input variables</a></span></li><li><span><a href=\"#Custom-activation-function\" data-toc-modified-id=\"Custom-activation-function-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Custom activation function</a></span></li><li><span><a href=\"#Definition-of-learning-rate\" data-toc-modified-id=\"Definition-of-learning-rate-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Definition of learning rate</a></span></li><li><span><a href=\"#Setup-the-model\" data-toc-modified-id=\"Setup-the-model-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Setup the model</a></span></li><li><span><a href=\"#Gradients\" data-toc-modified-id=\"Gradients-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Gradients</a></span></li><li><span><a href=\"#Print-model-information\" data-toc-modified-id=\"Print-model-information-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Print model information</a></span></li><li><span><a href=\"#Final-value-according-to-given-percentage\" data-toc-modified-id=\"Final-value-according-to-given-percentage-1.10\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span>Final value according to given percentage</a></span></li><li><span><a href=\"#Plot-loss-values-according-to-skipped-items-from-Backend-functionality-layer\" data-toc-modified-id=\"Plot-loss-values-according-to-skipped-items-from-Backend-functionality-layer-1.11\"><span class=\"toc-item-num\">1.11&nbsp;&nbsp;</span>Plot loss values according to skipped items from Backend functionality layer</a></span><ul class=\"toc-item\"><li><span><a href=\"#Legend-is-placed-outside-a-plot\" data-toc-modified-id=\"Legend-is-placed-outside-a-plot-1.11.1\"><span class=\"toc-item-num\">1.11.1&nbsp;&nbsp;</span>Legend is placed outside a plot</a></span></li></ul></li></ul></li><li><span><a href=\"#Additional/Optional-information\" data-toc-modified-id=\"Additional/Optional-information-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Additional/Optional information</a></span><ul class=\"toc-item\"><li><span><a href=\"#Possible-activation-function\" data-toc-modified-id=\"Possible-activation-function-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Possible activation function</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2oAc-WyJ6bsl",
    "outputId": "ff5981c6-3409-4e44-c126-3a69f7e54ded"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Concatenate, Dense, Input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keract; \n",
    "#   from keract import get_activations;\n",
    "#   from keract import get_gradients_of_activations;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "#tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of model topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VD(keras.layers.Layer):\n",
    "    def __init__(self, units=32, input_dim1=32, input_dim2 = 32):\n",
    "        super(VD, self).__init__()\n",
    "        \n",
    "        #input1 -> requirements\n",
    "        #input2 -> backend\n",
    "        \n",
    "        # weights for requirement signal\n",
    "        # trainable\n",
    "        w_init1 = tf.ones_initializer()\n",
    "        self.w1 = tf.Variable(\n",
    "            initial_value=w_init1(shape=(input_dim1, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        \n",
    "        # weights for backend signal\n",
    "        # trainable\n",
    "        w_init2 = tf.random_normal_initializer()\n",
    "        self.w2 = tf.Variable(\n",
    "            initial_value=w_init2(shape=(input_dim2, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        \n",
    "        # bias\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(\n",
    "            initial_value=b_init(shape=(units,), dtype=\"float32\"), trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs[0], self.w1) + self.b - tf.matmul(inputs[0], self.w1)* tf.matmul(inputs[1], self.w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of input parameters (graph edge weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_weights = [\n",
    "   np.array([\n",
    "        [0.1, 0.2, 0.2, 0.5],\n",
    "        [  0, 0.4, 0,   0.6],\n",
    "        [0.7, 0.3, 0,   0  ],\n",
    "        [  0, 0.3, 0.3, 0.4]\n",
    "   ]),\n",
    "   np.array([\n",
    "        [ 0.6,  0.4, 0,   0  ],\n",
    "        [ 0.6,  0.6, 0.8, 0.8],\n",
    "        [ 0.1,  0.1, 0.9, 0  ],\n",
    "        [ 0,    0,   0,   0.8],\n",
    "        [ 1,    1,   1,   1  ]\n",
    "   ]),\n",
    "   np.array([  0.00, 0.00, 0.00, 0.00]),\n",
    "   np.array([\n",
    "        [0.05, 0.00, 0.95],\n",
    "        [0.3,  0.3,  0.4],\n",
    "        [0.4,  0.0,  0.6],\n",
    "        [0.3,  0.0,  0.7]]),\n",
    "   np.array([0., 0., 0.]),\n",
    "   np.array([[0.8],\n",
    "             [0.5],\n",
    "             [  1]]),\n",
    "   np.array([0])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_data = np.array([[0.4,0.133,0.2,0.267]]);\n",
    "back_data = np.array([[0,0,0,0,0]]);\n",
    "tags_data = np.array([[0]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: percentage is global variable!\n",
    "def trade_off(x):\n",
    "    n = 1 / (1-percentage);\n",
    "    return(x - x**n/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of learning rate for \"Gradient descent (with momentum) optimizer\"\n",
    "LR = 0.01;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Input:\n",
    "#  percentage\n",
    "#  my_weights\n",
    "\n",
    "# input global variable \n",
    "#  percentage ... percentage in activation function\n",
    "\n",
    "# global variables used for setup custom layer names of the model \n",
    "relut_name = 'relu_activ_func';   \n",
    "tradeoff_name = 'trade_off_activ_func';\n",
    "output_name = 'output_layer';\n",
    "\n",
    "# Input parameters\n",
    "#  my_weights ... graph edge weights, topology of the model\n",
    "#\n",
    "def setup_model(my_weights):\n",
    "    \n",
    "    # the following variables can have arbitrary values (but distinguish)\n",
    "    #   for custom layer names of the model\n",
    "    requ1_name = 'requirement_layer_1';\n",
    "    requ2_name = 'requirement_layer_2';\n",
    "    back1_name = 'backend_layer_1';\n",
    "    back2_name = 'backend_layer_2';\n",
    "    edge_name  = 'edge_layer';\n",
    "    \n",
    "    # --- Model definition ---\n",
    "    # define two sets of inputs\n",
    "    input_req1 = Input(shape=(2,),name=requ1_name)\n",
    "    input_req2 = Input(shape=(2,),name=requ2_name)\n",
    "    input_req = Concatenate()([input_req1, input_req2])\n",
    "\n",
    "    # define backend functionalities\n",
    "    input_backend1 = Input(shape=(2,), name = back1_name)\n",
    "    input_backend2 = Input(shape=(3,), name = back2_name)\n",
    "    input_backend = Concatenate()([input_backend1, input_backend2])\n",
    "\n",
    "    input_req = Input(shape=(4,),name=requ1_name)\n",
    "    input_backend = Input(shape=(5,), name = back1_name)\n",
    "\n",
    "    # define middle level\n",
    "    middle = VD(4, 4, 5)([input_req,input_backend])\n",
    "    middle = Activation('relu', name=relut_name)(middle)\n",
    "    middle = Activation(trade_off, name=tradeoff_name)(middle)\n",
    "    edge = Dense(3, name = edge_name)(middle)\n",
    "\n",
    "    # define ouput level\n",
    "    output = Dense(1, name = output_name)(edge)\n",
    "    mymodel = Model(inputs=[input_req, input_backend], outputs=output)\n",
    "    opt = keras.optimizers.SGD(learning_rate=LR)\n",
    "\n",
    "    # --- Model compile ---\n",
    "    mymodel.compile(optimizer=opt, loss='mse');\n",
    "    \n",
    "    # --- Set model weights ---\n",
    "    mymodel.set_weights(my_weights);\n",
    "    \n",
    "    return(mymodel);\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the model 'mymodel' with given 'percentage' for activation function\n",
    "percentage = 0.8;\n",
    "mymodel = setup_model(my_weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined in previous cells: req_data, back_data, tags_data\n",
    "\n",
    "percentage = 0.8\n",
    "\n",
    "# Proposed (pecentage) input value for backend functionality (B1, B2, B3, B4, B5):\n",
    "prop_percentage = 1; # no backend functionality\n",
    "prop_percentage = 0; # all backend functionality are presented\n",
    "\n",
    "prop_percentage_array = [prop_percentage]*5;\n",
    "dtc = keract.get_gradients_of_activations(\n",
    "        mymodel, \n",
    "        [req_data, np.array([prop_percentage_array])],\n",
    "        tags_data,\n",
    "        output_format='simple');\n",
    "dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get value for key 'vd_1' or 'vd_2' or 'vd_3' or any 'vd_x' from the model calculation\n",
    "dtc_vd_value = next(vd_value for my_key,vd_value in dtc.items() if 'vd' in my_key);\n",
    "dtc_vd_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is supposed that keract.get_... is called 8 time before\n",
    "#   ... and vd == vd_8\n",
    "\n",
    "core_grad = dtc_vd_value*dtc[relut_name]*dtc[tradeoff_name];\n",
    "core_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"prop_percentage =\",prop_percentage);\n",
    "my_weights[0].dot(core_grad.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"prop_percentage =\",prop_percentage);\n",
    "my_weights[1].dot(core_grad.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print model information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model;\n",
    "plot_model(mymodel, show_shapes=True, show_layer_names=True, rankdir = 'LR', to_file = 'graph_value.pdf');\n",
    "plot_model(mymodel, show_shapes=True, show_layer_names=True, rankdir = 'LR') # print to Jupyter notebokk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final value according to given percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirement_name = ['Quality of life','Cardial','Posture','Activity'];\n",
    "backend_name = ['Smart shoes', 'Smart watch', 'Smart phone', 'O2','Cloud infrastructure'];\n",
    "\n",
    "def loss_value(mymodel, req_data, i_array):\n",
    "    return_loss_value = keract.get_activations(mymodel, [req_data, np.array([i_array])]);\n",
    "    return(return_loss_value);\n",
    "\n",
    "\n",
    "#\n",
    "# Input global variable: percentage\n",
    "#\n",
    "def print_final_value_perctentage(loss_percentage_array):\n",
    "    level_0_names = [requirement_name, backend_name]; \n",
    "    # we are eliminating only bavckend functionalities\n",
    "    level_0_names = [backend_name];\n",
    "    \n",
    "    # set up the model 'mymodel' \n",
    "    mymodel = setup_model(my_weights);\n",
    "    \n",
    "    # get output_name value without output_name type\n",
    "    print(\"{:.2f}\".format(loss_value(mymodel, \n",
    "                                     req_data, [0]*5)[output_name][0][0] \n",
    "                         ),\n",
    "          ': Final value with all backend functionalities');\n",
    "\n",
    "    for level_0_functionality in range(0,len(level_0_names)):\n",
    "        j = int(10 * percentage );\n",
    "    #    print('Percentage :',percentage*100,'%')\n",
    "        \n",
    "    #    print(level_0_functionality,level_0_names[level_0_functionality])\n",
    "        loss_percentage_array[0][j] = round(loss_value(mymodel, req_data, [0]*5)[output_name][0][0], 2);\n",
    "    #    print(' Final value with all backend functionalities:',loss_percentage_array[0][j])\n",
    "\n",
    "        loss_percentage_array[0][0] = 'Final value';\n",
    "        \n",
    "    \n",
    "        for i in range(0,len(level_0_names[level_0_functionality])):\n",
    "            funct_array    = [0]*len(level_0_names[level_0_functionality]);\n",
    "            funct_array[i] = 1;\n",
    "            \n",
    "            # get name of backend functionality\n",
    "            loss_percentage_array[i+1][0] = level_0_names[level_0_functionality][i];\n",
    "            \n",
    "            # get output_name value without output_name type\n",
    "            loss_percentage_array[i+1][j] = round(loss_value(mymodel, req_data, funct_array)[output_name][0][0], 2);\n",
    "            print('  ',\n",
    "    #             i,\n",
    "                  # get output_name value without output_name type\n",
    "                  \"{:.2f}\".format( loss_value(mymodel, req_data, funct_array)[output_name][0][0] ),\n",
    "                  ':',\n",
    "                  'Without',\n",
    "                  loss_percentage_array[i+1][0],\n",
    "    #              funct_array,\n",
    "                );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialize \n",
    "loss_percentage_array = [[0 for i in range(10)] for j in range(6)];\n",
    "\n",
    "# Note: percentage is global!\n",
    "for j in range(0,9):\n",
    "    percentage = (j+1)/10\n",
    "    # Write values\n",
    "    print(\"\\n{:n}% : defined percentage for trade off function\".format( percentage*100 ));\n",
    "    print(\"-\"*45);\n",
    "    \n",
    "    # percentage is parameter defined as GlOBAL variable\n",
    "    print_final_value_perctentage(loss_percentage_array); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_percentage_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss values according to skipped items from Backend functionality layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = 1/2.54;\n",
    "back_names = [loss_percentage_array[5][0]];\n",
    "plt.plot([*range(10,100,10)], loss_percentage_array[5][1:10]);\n",
    "for i in range(0,5):\n",
    "    print(loss_percentage_array[i][0]);\n",
    "    back_names.append(loss_percentage_array[i][0]);\n",
    "    plt.plot([*range(10,100,10)], loss_percentage_array[i][1:10]);\n",
    "plt.legend(back_names);\n",
    "\n",
    "plt.savefig('value_retained-1.pdf');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Legend is placed outside a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define plot size to place legend in the figure during 'savefig'\n",
    "fig = plt.figure(figsize=(7,4));\n",
    "\n",
    "cm = 1/2.54;\n",
    "back_names = [loss_percentage_array[5][0]];\n",
    "plt.plot([*range(10,100,10)], loss_percentage_array[5][1:10]);\n",
    "for i in range(0,5):\n",
    "    print(loss_percentage_array[i][0]);\n",
    "    back_names.append(loss_percentage_array[i][0]);\n",
    "    plt.plot([*range(10,100,10)], loss_percentage_array[i][1:10]);\n",
    "\n",
    "# put legend outside a plot\n",
    "legend_x = -0.5;\n",
    "legend_y = 0.5;\n",
    "plt.legend(back_names, loc='center left', bbox_to_anchor=(legend_x, legend_y))\n",
    "\n",
    "# bbox_inches = 'tight' : try to figure out the tight bbox of the figure\n",
    "plt.savefig('value_retained-left_legend.pdf', bbox_inches = 'tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define plot size to place legend in the figure during 'savefig'\n",
    "fig = plt.figure(figsize=(7,4));\n",
    "\n",
    "cm = 1/2.54;\n",
    "back_names = [loss_percentage_array[5][0]];\n",
    "plt.plot([*range(10,100,10)], loss_percentage_array[5][1:10]);\n",
    "for i in range(0,5):\n",
    "    print(loss_percentage_array[i][0]);\n",
    "    back_names.append(loss_percentage_array[i][0]);\n",
    "    plt.plot([*range(10,100,10)], loss_percentage_array[i][1:10]);\n",
    "\n",
    "# put legend outside a plot\n",
    "legend_x = 1;\n",
    "legend_y = 0.5;\n",
    "plt.legend(back_names, loc='center left', bbox_to_anchor=(legend_x, legend_y))\n",
    "\n",
    "# bbox_inches = 'tight' : try to figure out the tight bbox of the figure\n",
    "plt.savefig('value_retained.pdf', bbox_inches = 'tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional/Optional information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible activation function\n",
    "Requirements for activation function $y()$\n",
    "1. $y(0) = 0  $\n",
    "1. $y'(0) = 1 $\n",
    "1. $y(x) \\le x, \\; x \\in [0,1] $\n",
    "1. $y(1) = percentage $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "gs = gridspec.GridSpec(nrows=1, ncols=2)\n",
    "\n",
    "#\n",
    "# The first trade_off function\n",
    "#\n",
    "def trade_off_sample(x,percentage):\n",
    "    p = (np.tanh(1) - percentage)/(np.tanh(1)-1)\n",
    "    return(p*(x - np.tanh(x))+np.tanh(x))\n",
    "\n",
    "# 100 linearly spaced numbers\n",
    "x = np.linspace(0,1,100)\n",
    "\n",
    "# setting the axes at the centre\n",
    "\n",
    "ax0 = fig.add_subplot(gs[0, 0])\n",
    "ax0.spines['left'].set_position('zero')\n",
    "ax0.spines['bottom'].set_position('zero')\n",
    "ax0.spines['right'].set_color('none')\n",
    "ax0.spines['top'].set_color('none')\n",
    "ax0.xaxis.set_ticks_position('bottom')\n",
    "ax0.yaxis.set_ticks_position('left')\n",
    "\n",
    "# plot the indentiy function red\n",
    "y0 = x\n",
    "plt.plot(x,y0, 'r')\n",
    "# plot the 10% trade_off function function cyan\n",
    "y1 = trade_off_sample(x,0.1)\n",
    "plt.plot(x,y1, 'c')\n",
    "# plot all trade_off functions with percentage 20-90 blue\n",
    "for i in range(2,10):\n",
    "    plt.plot(x,trade_off_sample(x,i/10), 'b')\n",
    "\n",
    "plt.axvline(x=1, color='k', linestyle=(0, (1, 7)))\n",
    "plt.axhline(y=1, color='k', linestyle=(0, (1, 7)))\n",
    "\n",
    "#\n",
    "# The second trade_off function\n",
    "#\n",
    "n=2;\n",
    "def trade_off_sample(x,percentage):\n",
    "    n = 1 / (1-percentage);\n",
    "    y = x - x**n/n;\n",
    "    return(y)\n",
    "\n",
    "# 100 linearly spaced numbers\n",
    "x = np.linspace(0,1,100)\n",
    "\n",
    "# setting the axes at the centre\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 1])\n",
    "ax1.spines['left'].set_position('zero')\n",
    "ax1.spines['bottom'].set_position('zero')\n",
    "ax1.spines['right'].set_color('none')\n",
    "ax1.spines['top'].set_color('none')\n",
    "ax1.xaxis.set_ticks_position('bottom')\n",
    "ax1.yaxis.set_ticks_position('left')\n",
    "\n",
    "# plot the indentiy function red\n",
    "y0 = x\n",
    "plt.plot(x,y0, 'r')\n",
    "# plot the 10% trade_off function function cyan\n",
    "y1 = trade_off_sample(x,0.1)\n",
    "plt.plot(x,y1, 'c')\n",
    "# plot all trade_off functions with percentage 20-90 blue\n",
    "for i in range(2,10):\n",
    "    plt.plot(x,trade_off_sample(x,i/10), 'b')\n",
    "\n",
    "plt.axvline(x=1, color='k', linestyle=(0, (1, 7)))\n",
    "plt.axhline(y=1, color='k', linestyle=(0, (1, 7)))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "gs = gridspec.GridSpec(nrows=1, ncols=2)\n",
    "\n",
    "\n",
    "#\n",
    "# The second trade_off function\n",
    "#\n",
    "n=2;\n",
    "def trade_off_sample(x,percentage):\n",
    "    n = 1 / (1-percentage);\n",
    "    y = x - x**n/n;\n",
    "    return(y)\n",
    "\n",
    "# 100 linearly spaced numbers\n",
    "x = np.linspace(0,1,100)\n",
    "\n",
    "# setting the axes at the centre\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 1])\n",
    "ax1.spines['left'].set_position('zero')\n",
    "ax1.spines['bottom'].set_position('zero')\n",
    "ax1.spines['right'].set_color('none')\n",
    "ax1.spines['top'].set_color('none')\n",
    "#ax1.xaxis.set_ticks_position('bottom')\n",
    "#ax1.yaxis.set_ticks_position('left')\n",
    "\n",
    "# plot the indentiy function red\n",
    "y0 = x\n",
    "plt.plot(x,y0, 'r')\n",
    "# plot the 80% trade_off function function blue\n",
    "y1 = trade_off_sample(x,0.8)\n",
    "plt.plot(x,y1, 'b')\n",
    "\n",
    "plt.xticks(np.arange(0.2, 1.1, step=0.2))  # Set label locations.\n",
    "plt.yticks(np.arange(0.2, 1.1, step=0.2))  # Set label locations.\n",
    "\n",
    "plt.axvline(x=1, ymin=0.05, color='k', linestyle=(0, (1, 7)))\n",
    "plt.axhline(y=1, xmin=0.05, color='k', linestyle=(0, (1, 7)))\n",
    "plt.axhline(y=0.8, xmin=0.05, color='k', linestyle=(0, (1, 7)))\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "myfirstNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "VG",
   "language": "python",
   "name": "vg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "452.997px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
